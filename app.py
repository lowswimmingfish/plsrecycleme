import streamlit as st
import pandas as pd
from PIL import Image
import numpy as np
import openai
import io
import matplotlib.pyplot as plt
from datetime import datetime
import matplotlib
import os

# âœ… í•œê¸€ í°íŠ¸ ì„¤ì •
matplotlib.rcParams['font.family'] = 'AppleGothic'
matplotlib.rcParams['axes.unicode_minus'] = False

# âœ… í™˜ê²½ ë¶„ê¸°
is_cloud = os.environ.get("STREAMLIT_CLOUD", "false").lower() == "true"

# âœ… OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
if "openai" in st.secrets and "api_key" in st.secrets["openai"]:
    openai.api_key = st.secrets["openai"]["api_key"]
else:
    st.stop()

if not is_cloud:
    import pytesseract

# âœ… GPT í”„ë¡¬í”„íŠ¸ (ê°„í¸ì¥ë¶€ ê¸°ì¤€)
def ask_gpt_for_journal_entries(ocr_text):
    system_prompt = (
        "ë„ˆëŠ” ì†Œê·œëª¨ ë™ì•„ë¦¬/ëª¨ì„ì˜ íšŒê³„ ë‹´ë‹¹ìì•¼. ì´ ëª¨ì„ì€ ì˜ë¦¬ í™œë™ì„ í•˜ì§€ ì•Šê³ , "
        "íšŒì› íšŒë¹„ë‚˜ ê°„ë‹¨í•œ ì™¸ë¶€ ì§€ì›ê¸ˆìœ¼ë¡œ ìš´ì˜ë¼. ë”°ë¼ì„œ ê¸°ì—… íšŒê³„ì—ì„œ ì“°ëŠ” 'ë§¤ì¶œ', 'ìˆ˜ìµ', 'ë¹„ìš©' ê°™ì€ ìš©ì–´ëŠ” ì“°ë©´ ì•ˆ ë¼.\n\n"
        "ì§€ì¶œì€ í–‰ì‚¬ë¹„, ì‹ë¹„, êµí†µë¹„, ì†Œëª¨í’ˆë¹„, ë¬¼í’ˆêµ¬ì…ë¹„ ë“±ìœ¼ë¡œ êµ¬ë¶„í•˜ê³ , "
        "ì…ê¸ˆì€ íšŒë¹„ìˆ˜ì…, ì§€ì›ê¸ˆ, ê°œì¸ì„ ë‚©ê¸ˆ ë“±ìœ¼ë¡œ ë¶„ë¥˜í•´ì¤˜.\n\n"
        "ê²°ê³¼ëŠ” í‘œë¡œ ì •ë¦¬í•´ì¤˜ ì´ê²Œ ë§¤ìš° ì¤‘ìš”í•´. í•­ëª©ëª… / ê³„ì •ê³¼ëª© / ì°¨ë³€ ë˜ëŠ” ëŒ€ë³€ / ê¸ˆì•¡ í˜•ì‹ìœ¼ë¡œ.\n\n"
        "ì˜ˆì‹œ:\n"
        "- í¸ì˜ì  ê°„ì‹ êµ¬ì… â†’ í•­ëª©ëª…: ê°„ì‹, ê³„ì •ê³¼ëª©: ì‹ë¹„, ì°¨ë³€, 7,000ì›\n"
        "- íšŒë¹„ ì…ê¸ˆ â†’ í•­ëª©ëª…: íšŒë¹„ì…ê¸ˆ, ê³„ì •ê³¼ëª©: íšŒë¹„ìˆ˜ì…, ëŒ€ë³€, 10,000ì›\n"
        "- ì¹´ë“œê²°ì œ â†’ ê³„ì •ê³¼ëª©: ë³´í†µì˜ˆê¸ˆ ë˜ëŠ” ì¹´ë“œ, ëŒ€ë³€\n"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": ocr_text}
    ]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"âš ï¸ GPT ìš”ì²­ ì‹¤íŒ¨: {e}"

# âœ… GPT ë§ˆí¬ë‹¤ìš´ í‘œ íŒŒì‹± í•¨ìˆ˜
def parse_markdown_table(markdown_text):
    try:
        lines = markdown_text.strip().split("\n")
        table_lines = [line for line in lines if "|" in line]
        if len(table_lines) < 2:
            return pd.DataFrame()

        table = "\n".join(table_lines)
        df = pd.read_csv(io.StringIO(table), sep="|", engine="python", skipinitialspace=True)
        df = df.dropna(axis=1, how="all")
        df.columns = [col.strip() for col in df.columns]
        df = df.drop(df.index[0])
        df = df.reset_index(drop=True)
        return df
    except Exception as e:
        st.warning(f"âš ï¸ í‘œ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

# âœ… Streamlit UI ì‹œì‘
st.title("ğŸ“¸ ìë™ë¶„ê°œ ì‹œìŠ¤í…œ")

uploaded_files = st.file_uploader("ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ ì—…ë¡œë“œ", accept_multiple_files=True, type=["png", "jpg", "jpeg"])

all_dataframes = []

if uploaded_files:
    for file in uploaded_files:
        image = Image.open(file)
        st.image(image, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", use_container_width=True)

        if is_cloud:
            text = st.text_area("âœï¸ Cloud í™˜ê²½ì—ì„œëŠ” OCR ë¯¸ì§€ì›. í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”", "", height=200, key=file.name)
        else:
            img = image.convert("L")
            img = img.resize((img.width * 2, img.height * 2))
            text = pytesseract.image_to_string(img, lang="kor+eng")
            text = st.text_area("ğŸ“œ OCR ê²°ê³¼ (ìˆ˜ì • ê°€ëŠ¥)", text, height=200, key=file.name)

        if st.button(f"ğŸ¤– GPT ì¬ìš”ì²­ ({file.name})"):
            gpt_result = ask_gpt_for_journal_entries(text)
            st.session_state[f"gpt_result_{file.name}"] = gpt_result

        gpt_result = st.session_state.get(f"gpt_result_{file.name}", ask_gpt_for_journal_entries(text))

        st.subheader("ğŸ¤– GPT ìë™ë¶„ê°œ ê²°ê³¼")
        st.text_area("GPT ì‘ë‹µ", gpt_result, height=300, key=f"gpt_out_{file.name}")

        df = parse_markdown_table(gpt_result)
        if not df.empty:
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            df["ìˆ˜ì •ì‹œê°„"] = now
            st.subheader("ğŸ“Š ìë™ë¶„ê°œ í‘œ (ìˆ˜ì • ê°€ëŠ¥)")
            edited_df = st.data_editor(df, num_rows="dynamic", key=f"editor_{file.name}")

            csv = edited_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ’¾ CSVë¡œ ì €ì¥í•˜ê¸°",
                data=csv,
                file_name=f"auto_journal_{file.name}.csv",
                mime="text/csv",
            )

            all_dataframes.append(edited_df)

if all_dataframes:
    df_concat = pd.concat(all_dataframes, ignore_index=True)
    try:
        df_concat["ê¸ˆì•¡"] = df_concat["ê¸ˆì•¡"].astype(str).str.replace(",", "").str.replace("ì›", "").str.strip()
        df_concat["ê¸ˆì•¡"] = pd.to_numeric(df_concat["ê¸ˆì•¡"], errors="coerce")

        debit_col = None
        for col in df_concat.columns:
            if "ì°¨ë³€" in col and "ëŒ€ë³€" in col:
                debit_col = col
                break

        if debit_col is None:
            raise ValueError("â€˜ì°¨ë³€ ë˜ëŠ” ëŒ€ë³€â€™ ê´€ë ¨ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

        debit_df = df_concat[df_concat[debit_col].str.contains("ì°¨ë³€", na=False)]
        grouped = debit_df.groupby("ê³„ì •ê³¼ëª©")["ê¸ˆì•¡"].sum()

        fig, ax = plt.subplots(figsize=(6, 6))
        wedges, texts, autotexts = ax.pie(grouped, labels=grouped.index, autopct="%1.1f%%", startangle=90, textprops=dict(color="black"))
        ax.axis("equal")
        st.subheader("ğŸ¥§ ê³„ì •ê³¼ëª©ë³„ ì§€ì¶œ ë¹„ìœ¨")
        st.pyplot(fig)
    except Exception as e:
        st.warning(f"Pie chart ì‹œê°í™” ì‹¤íŒ¨: {e}")
